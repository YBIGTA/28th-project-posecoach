"""
ìš´ë™ ì˜ìƒ ë¶„ì„ ì„œë²„
ì˜ìƒ ì—…ë¡œë“œ â†’ í”„ë ˆì„ ì¶”ì¶œ â†’ YOLO26n-pose í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ â†’ ê·œì¹™ ê¸°ë°˜ ìì„¸ ë¶„ì„ â†’ í”¼ë“œë°±
"""
import sys
import json
from pathlib import Path

import streamlit as st
import cv2
import numpy as np
import pandas as pd

# ê¸°ì¡´ preprocess ëª¨ë“ˆ import ê²½ë¡œ ì„¤ì •
ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(ROOT / "preprocess"))
sys.path.insert(0, str(ROOT / "preprocess" / "scripts"))
sys.path.insert(0, str(ROOT))

from config import (
    UPLOAD_VIDEO_DIR, OUT_FRAMES_DIR, OUT_FRAMES_MP_DIR,
    FRAME_EXTRACT_FPS, TARGET_RESOLUTION,
)
from video_preprocess import extract_frames
from extract_yolo_frames import process_single_frame
from utils.keypoints import load_pose_model, COCO_KEYPOINT_MAP
from utils.visualization import draw_skeleton_on_frame

# í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì—†ìœ¼ë©´ ds_modules/__init__.pyì— ì¶”ê°€í•˜ê±°ë‚˜ ì§ì ‘ íŒŒì¼ì—ì„œ import)
from ds_modules import (
    compute_virtual_keypoints, normalize_pts,
    KeypointSmoother, 
    PushUpCounter, PullUpCounter,
    PushUpEvaluator, PullUpEvaluator, 
)

# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ìš´ë™ ì˜ìƒ ë¶„ì„", layout="wide")
st.title("ìš´ë™ ì˜ìƒ ë¶„ì„")

# â”€â”€ ì‚¬ì´ë“œë°” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì„¤ì •")
    exercise_type = st.selectbox("ìš´ë™ ì¢…ë¥˜", [
        "í‘¸ì‹œì—…", "í’€ì—…"])
    extract_fps = st.slider("í”„ë ˆì„ ì¶”ì¶œ FPS", min_value=1, max_value=3,
                            value=FRAME_EXTRACT_FPS)
    st.caption(f"í•´ìƒë„: {TARGET_RESOLUTION[0]}x{TARGET_RESOLUTION[1]} (FHD)")
    st.caption("ëª¨ë¸: YOLO26n-pose (COCO 17 í‚¤í¬ì¸íŠ¸)")

# â”€â”€ YOLO ëª¨ë¸ ìºì‹± ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def get_pose_model():
    return load_pose_model()

# â”€â”€ 1. ì˜ìƒ ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.header("1. ì˜ìƒ ì—…ë¡œë“œ")
uploaded = st.file_uploader(
    "ë¶„ì„í•  ìš´ë™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš” (MP4, AVI, MOV, MKV, WEBM)",
    type=["mp4", "avi", "mov", "mkv", "webm"],
)

if uploaded is not None:
    # íŒŒì¼ í¬ê¸° ê²€ì¦ (500MB)
    if uploaded.size > 500 * 1024 * 1024:
        st.error("íŒŒì¼ í¬ê¸°ê°€ 500MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        st.stop()

    st.video(uploaded)

    # ì—…ë¡œë“œ íŒŒì¼ ì €ì¥
    UPLOAD_VIDEO_DIR.mkdir(parents=True, exist_ok=True)
    video_save_path = UPLOAD_VIDEO_DIR / uploaded.name
    with open(video_save_path, "wb") as f:
        f.write(uploaded.getbuffer())

    video_stem = video_save_path.stem
    frames_dir = OUT_FRAMES_DIR / video_stem

    # â”€â”€ 2. ë¶„ì„ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.header("2. ë¶„ì„ ì‹¤í–‰")

    if st.button("ë¶„ì„ ì‹œì‘", type="primary"):
        # Step 1: í”„ë ˆì„ ì¶”ì¶œ
        st.subheader("Step 1: í”„ë ˆì„ ì¶”ì¶œ")
        progress_frames = st.progress(0, text="í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")

        cap = cv2.VideoCapture(str(video_save_path))
        src_fps = cap.get(cv2.CAP_PROP_FPS)
        total_src_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        src_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        src_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = total_src_frames / src_fps if src_fps > 0 else 0
        cap.release()

        extracted_count = extract_frames(
            video_save_path, frames_dir, extract_fps, TARGET_RESOLUTION
        )
        progress_frames.progress(100, text=f"í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {extracted_count}ê°œ")

        # Step 2: YOLO26n-pose í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
        st.subheader("Step 2: í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (YOLO26n-pose)")
        progress_kp = st.progress(0, text="í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì¤‘...")

        frame_files = sorted(
            f for f in frames_dir.iterdir()
            if f.suffix.lower() in {".jpg", ".png", ".jpeg"}
        )

        pose_model = get_pose_model()
        all_keypoints = []
        success_count = 0

        for i, fpath in enumerate(frame_files):
            pts = process_single_frame(pose_model, fpath)
            all_keypoints.append({
                "frame_idx": i,
                "img_key": fpath.name,
                "img_path": str(fpath),
                "pts": pts,
            })
            if pts is not None:
                success_count += 1

            pct = int((i + 1) / len(frame_files) * 100)
            progress_kp.progress(pct, text=f"í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì¤‘... {i+1}/{len(frame_files)}")

        progress_kp.progress(100, text=f"í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {success_count}/{len(frame_files)}")

        # Step 3: ìì„¸ ë¶„ì„
        st.subheader("Step 3: ìì„¸ ë¶„ì„")
        progress_eval = st.progress(0, text="ìì„¸ ë¶„ì„ ì¤‘...")

        # í”„ë ˆì„ í•´ìƒë„
        sample_img = cv2.imread(str(frame_files[0])) if frame_files else None
        if sample_img is not None:
            img_h, img_w = sample_img.shape[:2]
        else:
            img_w, img_h = TARGET_RESOLUTION

        # ì¹´ìš´í„°/í‰ê°€ê¸°/ìŠ¤ë¬´ë” ì´ˆê¸°í™”
        smoother = KeypointSmoother(window=3)
        
        # ì„ íƒëœ ìš´ë™ì— ë”°ë¼ í´ë˜ìŠ¤ í• ë‹¹
        if exercise_type == "í‘¸ì‹œì—…":
            counter = PushUpCounter()
            evaluator = PushUpEvaluator()
        elif exercise_type == "í’€ì—…":
            counter = PullUpCounter()
            evaluator = PullUpEvaluator()
        else:
            # ê¸°ë³¸ê°’ (í˜¹ì€ ì—ëŸ¬ ì²˜ë¦¬)
            counter = PushUpCounter()
            evaluator = PushUpEvaluator()

        frame_scores = []
        error_frames = []

        for i, kp_data in enumerate(all_keypoints):
            pts = kp_data["pts"]
            # ê°€ìƒ í‚¤í¬ì¸íŠ¸ ìƒì„± â†’ ìŠ¤ë¬´ë”© â†’ ì •ê·œí™”
            flat = compute_virtual_keypoints(pts)
            smoothed = smoother.smooth(flat)
            npts = normalize_pts(smoothed, img_w, img_h) if smoothed else None

            # 1. ì¹´ìš´í„° ìƒíƒœ ì—…ë°ì´íŠ¸ (ì¤€ë¹„ ì™„ë£Œ ì—¬ë¶€ íŒë³„)
            counter.update(npts)

            # 2. ìƒíƒœì— ë”°ë¥¸ ì²˜ë¦¬ (Activeì¼ ë•Œë§Œ í‰ê°€)
            status_text = "ì¤€ë¹„ ì¤‘..."
            
            if counter.is_active:
                status_text = f"ìš´ë™ ì¤‘ (Count: {counter.count})"
                
                # ìì„¸ í‰ê°€ ì‹¤í–‰
                result = evaluator.evaluate(npts)

                # ì ìˆ˜ ê¸°ë¡
                frame_scores.append({
                    "frame_idx": i,
                    "score": result["score"],
                    "errors": result["errors"],
                    "details": result["details"],
                })

                # ì˜¤ë¥˜ê°€ ìˆëŠ” í”„ë ˆì„ ë³„ë„ ê¸°ë¡
                if result["errors"] and result["errors"] != ["í‚¤í¬ì¸íŠ¸ ì—†ìŒ"]:
                    error_frames.append({
                        "frame_idx": i,
                        "img_key": kp_data["img_key"],
                        "img_path": kp_data["img_path"],
                        "score": result["score"],
                        "errors": result["errors"],
                        "details": result["details"],
                        "pts": pts,
                    })
            
            else:
                # ì¤€ë¹„ ì¤‘: ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ ë“±
                frames_left = max(0, counter.active_threshold - counter.ready_frames)
                if counter.ready_frames > 0:
                    status_text = f"ì¤€ë¹„ ìì„¸ ìœ ì§€ ì¤‘... ({counter.ready_frames}/{counter.active_threshold})"
                else:
                    status_text = "ëŒ€ê¸° ì¤‘ (ì¤€ë¹„ ìì„¸ë¥¼ ì·¨í•´ì£¼ì„¸ìš”)"

            pct = int((i + 1) / len(all_keypoints) * 100)
            progress_eval.progress(pct, text=f"[{status_text}] {i+1}/{len(all_keypoints)}")

        progress_eval.progress(100, text="ìì„¸ ë¶„ì„ ì™„ë£Œ!")

        # ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
        st.session_state["results"] = {
            "video_name": video_stem,
            "exercise_type": exercise_type,
            "total_frames": len(frame_files),
            "success_count": success_count,
            "fps": extract_fps,
            "resolution": list(TARGET_RESOLUTION),
            "src_resolution": [src_w, src_h],
            "duration": round(duration, 1),
            "keypoints": all_keypoints,
            "exercise_count": counter.count,
            "frame_scores": frame_scores,
            "error_frames": error_frames,
        }

        st.success("ë¶„ì„ ì™„ë£Œ!")

    # â”€â”€ 3. ê²°ê³¼ ëŒ€ì‹œë³´ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "results" in st.session_state:
        res = st.session_state["results"]
        kp_list = res["keypoints"]
        frame_scores = res.get("frame_scores", [])
        error_frames = res.get("error_frames", [])

        st.header("3. ë¶„ì„ ê²°ê³¼")

        # [ê²½ê³ ] ë¶„ì„ëœ í”„ë ˆì„ì´ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš° (ì¤€ë¹„ ë™ì‘ ì¸ì‹ ì‹¤íŒ¨ ë“±)
        if not frame_scores:
            st.warning("âš ï¸ ìš´ë™ ë™ì‘ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("""
            **ê°€ëŠ¥í•œ ì›ì¸:**
            1. ì¤€ë¹„ ìì„¸(ì‹œì‘ ìì„¸)ê°€ ì§§ì•„ì„œ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
            2. ì„¤ì •ëœ ìš´ë™ ì¢…ë¥˜ì™€ ì‹¤ì œ ì˜ìƒì´ ë‹¤ë¦…ë‹ˆë‹¤.
            3. ì¹´ë©”ë¼ì— ì „ì‹ ì´ ë‚˜ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
            
            ğŸ‘‰ `exercise_counter.py`ì˜ `active_threshold` ê°’ì„ ë” ë‚®ì¶”ê±°ë‚˜, ì˜ìƒì„ í™•ì¸í•´ì£¼ì„¸ìš”.
            """)

        # â”€â”€ ë©”íŠ¸ë¦­ ì¹´ë“œ â”€â”€
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ì´ í”„ë ˆì„", f"{res['total_frames']}ê°œ")
        c2.metric("í‚¤í¬ì¸íŠ¸ ì„±ê³µ", f"{res['success_count']}ê°œ")
        c3.metric("ì¶”ì¶œ FPS", f"{res['fps']}fps")
        c4.metric("í•´ìƒë„", f"{res['resolution'][0]}x{res['resolution'][1]}")

        # â”€â”€ ìì„¸ ë¶„ì„ ë©”íŠ¸ë¦­ (Step 3 ê²°ê³¼) â”€â”€
        if frame_scores:
            st.divider()
            m1, m2, m3 = st.columns(3)
            m1.metric(f"{res.get('exercise_type', 'ìš´ë™')} íšŸìˆ˜",
                      f"{res.get('exercise_count', 0)}íšŒ")
            m2.metric("ì˜¤ë¥˜ í”„ë ˆì„",
                      f"{len(error_frames)}ê°œ",
                      delta=f"{len(error_frames)}/{res['total_frames']}",
                      delta_color="inverse")

            scores = [fs["score"] for fs in frame_scores]
            avg_score = sum(scores) / len(scores) if scores else 0
            m3.metric("í‰ê·  ìì„¸ ì ìˆ˜", f"{avg_score:.0%}")

            # â”€â”€ í”„ë ˆì„ë³„ ì ìˆ˜ ì°¨íŠ¸ â”€â”€
            st.divider()
            st.subheader("í”„ë ˆì„ë³„ ìì„¸ ì ìˆ˜")
            chart_df = pd.DataFrame({
                "í”„ë ˆì„": [fs["frame_idx"] for fs in frame_scores],
                "ì ìˆ˜": scores,
            })
            st.line_chart(chart_df, x="í”„ë ˆì„", y="ì ìˆ˜")

            # â”€â”€ ì˜¤ë¥˜ í”„ë ˆì„ ë¸Œë¼ìš°ì € â”€â”€
            if error_frames:
                st.divider()
                st.subheader("ì˜¤ë¥˜ í”„ë ˆì„ ìƒì„¸")

                error_options = [
                    f"í”„ë ˆì„ {ef['frame_idx']} (ì ìˆ˜: {ef['score']:.0%}) â€” {', '.join(ef['errors'][:2])}"
                    for ef in error_frames
                ]
                selected_idx = st.selectbox("ì˜¤ë¥˜ í”„ë ˆì„ ì„ íƒ", range(len(error_options)),
                                            format_func=lambda i: error_options[i])

                ef = error_frames[selected_idx]

                col_img, col_fb = st.columns([1, 1])

                with col_img:
                    st.markdown("**ìŠ¤ì¼ˆë ˆí†¤ ì˜¤ë²„ë ˆì´**")
                    if ef["pts"] is not None:
                        skel_img = draw_skeleton_on_frame(ef["img_path"], ef["pts"])
                        if skel_img is not None:
                            st.image(skel_img, use_container_width=True)
                        else:
                            st.warning("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("í‚¤í¬ì¸íŠ¸ ì—†ìŒ")

                with col_fb:
                    st.markdown("**í”¼ë“œë°±**")
                    st.markdown(f"**í”„ë ˆì„**: {ef['frame_idx']}")
                    st.markdown(f"**ìì„¸ ì ìˆ˜**: {ef['score']:.0%}")

                    for err_msg in ef["errors"]:
                        st.error(err_msg)

                    if ef["details"]:
                        st.markdown("**ìƒì„¸ ìˆ˜ì¹˜**")
                        for check_name, detail in ef["details"].items():
                            icon = "âœ…" if detail["status"] == "ok" else "âš ï¸" if detail["status"] == "warning" else "âŒ"
                            st.markdown(
                                f"{icon} **{check_name}**: {detail['value']}  \n"
                                f"â†’ {detail['feedback']}"
                            )

        st.divider()

        # â”€â”€ í”„ë ˆì„ ì„ íƒ ìŠ¬ë¼ì´ë” â”€â”€
        if res["total_frames"] > 0:
            st.subheader("í”„ë ˆì„ ë¸Œë¼ìš°ì €")
            frame_idx = st.slider(
                "í”„ë ˆì„ ì„ íƒ", 0, res["total_frames"] - 1, 0,
                format="í”„ë ˆì„ %d",
            )

            selected = kp_list[frame_idx]
            img_path = selected["img_path"]
            pts = selected["pts"]

            # 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ: ì›ë³¸ | ìŠ¤ì¼ˆë ˆí†¤
            col_orig, col_skel = st.columns(2)

            with col_orig:
                st.markdown("**ì›ë³¸ í”„ë ˆì„**")
                orig_img = cv2.imread(img_path)
                if orig_img is not None:
                    st.image(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB),
                             use_container_width=True)
                else:
                    st.warning("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            with col_skel:
                st.markdown("**ìŠ¤ì¼ˆë ˆí†¤ ì˜¤ë²„ë ˆì´**")
                if pts is not None:
                    skel_img = draw_skeleton_on_frame(img_path, pts)
                    if skel_img is not None:
                        st.image(skel_img, use_container_width=True)
                    else:
                        st.warning("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì´ í”„ë ˆì„ì—ì„œ í‚¤í¬ì¸íŠ¸ë¥¼ ê²€ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # í•´ë‹¹ í”„ë ˆì„ ìì„¸ ì ìˆ˜ í‘œì‹œ
            if frame_scores:
                # frame_scoresëŠ” activeëœ í”„ë ˆì„ë§Œ ë“¤ì–´ìˆìœ¼ë¯€ë¡œ, í˜„ì¬ ìŠ¬ë¼ì´ë”ì˜ frame_idxì™€ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ì°¾ì•„ì•¼ í•¨
                # ë°©ë²•: frame_scores ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                target_score = next((fs for fs in frame_scores if fs["frame_idx"] == frame_idx), None)
                
                if target_score:
                    st.markdown(f"**ì´ í”„ë ˆì„ ìì„¸ ì ìˆ˜**: {target_score['score']:.0%}")
                    if target_score["errors"]:
                        for err in target_score["errors"]:
                            st.warning(err)
                else:
                    st.info("ì´ í”„ë ˆì„ì€ ë¶„ì„ ëŒ€ìƒ(Active) êµ¬ê°„ì´ ì•„ë‹™ë‹ˆë‹¤. (ì¤€ë¹„ ì¤‘ í˜¹ì€ ì¢…ë£Œ)")

            # í‚¤í¬ì¸íŠ¸ í…Œì´ë¸”
            if pts is not None:
                with st.expander("í‚¤í¬ì¸íŠ¸ ìƒì„¸"):
                    rows = []
                    for name, pt in pts.items():
                        rows.append({
                            "ê´€ì ˆëª…": name,
                            "x": pt["x"],
                            "y": pt["y"],
                            "confidence": pt["vis"],
                        })
                    df = pd.DataFrame(rows)
                    st.dataframe(df, use_container_width=True, hide_index=True)

            # JSON ë‹¤ìš´ë¡œë“œ
            st.divider()
            
            # ì•ˆì „í•œ í‰ê·  ì ìˆ˜ ê³„ì‚°
            avg_score_val = 0
            if frame_scores:
                avg_score_val = sum(fs["score"] for fs in frame_scores) / len(frame_scores)

            export_data = {
                "video": res["video_name"],
                "exercise_type": res.get("exercise_type", ""),
                "exercise_count": res.get("exercise_count", 0),
                "resolution": res["resolution"],
                "fps": res["fps"],
                "total_frames": res["total_frames"],
                "extracted_keypoints": res["success_count"],
                "avg_posture_score": round(avg_score_val, 2) if frame_scores else None,
                "error_frame_count": len(error_frames),
                "frames": [
                    {
                        "frame_idx": kp["frame_idx"],
                        "img_key": kp["img_key"],
                        "pts": kp["pts"],
                    }
                    for kp in kp_list
                    if kp["pts"] is not None
                ],
            }
            json_str = json.dumps(export_data, indent=2, ensure_ascii=False)
            st.download_button(
                label="ë¶„ì„ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_str,
                file_name=f"{res['video_name']}_analysis.json",
                mime="application/json",
            )