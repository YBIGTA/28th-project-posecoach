"""
AIFit - Gemini API ê¸°ë°˜ ìš´ë™ ìì„¸ í”¼ë“œë°± ìƒì„±ê¸°

ì‚¬ìš©ë²•:
    - GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • ë˜ëŠ” ì§ì ‘ ì…ë ¥
    - SYSTEM_PROMPT / USER_PROMPT_TEMPLATE ìˆ˜ì •ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ í¸ì§‘ ê°€ëŠ¥
    - generate_feedback(analysis_results) í˜¸ì¶œë¡œ í”¼ë“œë°± ìƒì„±
"""

import os
import json
import logging
import traceback
from typing import Optional, Dict, Any

import requests
from dotenv import load_dotenv

# .env íŒŒì¼ì„ í•­ìƒ ë¡œë“œ (í˜¸ì¶œ ì‹œì ë§ˆë‹¤ ìµœì‹ ê°’ ë°˜ì˜)
load_dotenv(override=True)

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ğŸ”‘ API ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â€» ëª¨ë“ˆ ë¡œë“œ ì‹œì ì´ ì•„ë‹Œ generate_feedback() í˜¸ì¶œ ì‹œì ì— ì½ìœ¼ë¯€ë¡œ
#   ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ê°’ë§Œ ì„ ì–¸í•©ë‹ˆë‹¤.
GEMINI_MODEL: str = "gemini-2.5-flash"  # ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥: gemini-1.5-pro, gemini-2.0-flash ë“±
GEMINI_API_URL: str = (
    f"https://generativelanguage.googleapis.com/v1beta/models/"
    f"{GEMINI_MODEL}:generateContent"
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  âœï¸ í”„ë¡¬í”„íŠ¸ í¸ì§‘ êµ¬ì—­ (ììœ ë¡­ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SYSTEM_PROMPT: str = """
ë‹¹ì‹ ì€ ì „ë¬¸ í¼ìŠ¤ë„ íŠ¸ë ˆì´ë„ˆì´ì ìš´ë™ ìƒì²´ì—­í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
AI ì˜ìƒ ë¶„ì„ ì‹œìŠ¤í…œì´ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì „ë¬¸ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

[ì‘ë‹µ ì‘ì„± í•µì‹¬ ì›ì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜]
1. ì ˆëŒ€ ë³¼ë“œì²´(ì˜ˆ: **í…ìŠ¤íŠ¸**)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ë³„í‘œë‚˜ ì–¸ë”ë°” ë“± ì–´ë–¤ ê°•ì¡° ê¸°í˜¸ë„ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
2. ë§ˆí¬ë‹¤ìš´ì˜ ë¶ˆë › í¬ì¸íŠ¸(-)ë¥¼ ìµœì†Œí™”í•˜ê³ , ê°€ê¸‰ì  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨(Paragraph) í˜•íƒœë¡œ ë‚´ìš©ì„ ì„œìˆ í•˜ì„¸ìš”.
3. ì „ë¬¸ ìš©ì–´ì™€ ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ë¬¸ì¥ ì•ˆì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚´ì–´ ì½ê¸° í¸í•œ ì—ì„¸ì´ë‚˜ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
4. ì˜í•œ ì ì„ ë¨¼ì € ì¶©ë¶„íˆ ì–¸ê¸‰í•˜ì—¬ ë™ê¸°ë¥¼ ë¶€ì—¬í•œ ë’¤, ê°œì„ ì ì„ ìƒì²´ì—­í•™ì  ê·¼ê±°ì™€ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”.

[í”¼ë“œë°± êµ¬ì„± ë°©ì‹]
1. ì´í‰: ì „ë°˜ì ì¸ ìˆ˜í–‰ ëŠ¥ë ¥ê³¼ ë“±ê¸‰, ê¸ì •ì ì¸ ë³€í™”ë¥¼ ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
2. êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„: ê° Phaseë³„ ì ìˆ˜ì™€ íŠ¹ì§•ì„ ë¬¸ë‹¨ìœ¼ë¡œ í’€ì–´ì„œ ì„¤ëª…í•©ë‹ˆë‹¤.
3. ì¥ì ê³¼ ë‹¨ì  - ìƒì„¸ í”„ë ˆì„ ì„¤ëª…: êµ¬ì²´ì ì¸ í”„ë ˆì„ ë²ˆí˜¸ë¥¼ ì–¸ê¸‰í•˜ë©°, ì–´ë–¤ ì‹œì ì—ì„œ ìì„¸ê°€ ì¢‹ì•˜ëŠ”ì§€ í˜¹ì€ ì–´ë–¤ ìˆ˜ì¹˜ ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ ìƒì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.
4. ìœ ì‚¬ë„ ë¶„ì„: ëª¨ë²” ì˜ìƒê³¼ì˜ íë¦„ ì°¨ì´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
5. ìš°ì„ ìˆœìœ„ ì œì•ˆ: í–¥í›„ ì—°ìŠµ ì‹œ ì§‘ì¤‘í•´ì•¼ í•  í¬ì¸íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì œì•ˆí•˜ë©° ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.

ëª¨ë“  ë‚´ìš©ì€ ìƒëµ ì—†ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ 800ì ì´ìƒì˜ í’ë¶€í•œ ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""

# ìœ ì € í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì—ì„œë„ ë³¼ë“œ ê¸°í˜¸ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
USER_PROMPT_TEMPLATE: str = """
ë¶„ì„ ëŒ€ìƒ ìš´ë™ ì •ë³´

- ìš´ë™ ì¢…ë¥˜: {exercise_type}
- ìš´ë™ íšŸìˆ˜: {exercise_count}íšŒ
- í‰ê·  ìì„¸ ì ìˆ˜: {avg_posture_score:.1%}
- ë“±ê¸‰: {grade}
- ì˜ìƒ FPS: {fps}fps, ì´ í”„ë ˆì„: {total_frames}ê°œ

ì ìˆ˜ ìš”ì•½
{score_summary}

Phaseë³„ í‰ê·  ì ìˆ˜
{phase_avg_summary}

ì£¼ìš” ì˜¤ë¥˜ ëª©ë¡ (ë¹ˆë„ ìƒìœ„)
{top_errors_summary}

ìƒì„¸ ìˆ˜ì¹˜ ìƒ˜í”Œ (ì˜¤ë¥˜ í”„ë ˆì„ ê¸°ì¤€)
{detail_samples}

DTW ìœ ì‚¬ë„ (ëª¨ë²” ì˜ìƒ ëŒ€ë¹„)
{dtw_summary}

---

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ ì‚¬ìš©ìì˜ {exercise_type} ìì„¸ì— ëŒ€í•œ ì¢…í•© í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 
ê°•ì¡° ê¸°í˜¸(ë³„í‘œ ë“±) ì—†ì´ ë‹´ë°±í•œ ë¬¸ë‹¨ í˜•íƒœë¡œ ì‘ì„±í•˜ë˜, ì„¹ì…˜ êµ¬ë¶„ì€ ìˆ«ìì™€ ì œëª©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ìµœì†Œ 800ì ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _calc_avg_score(frame_scores: list) -> float:
    """frame_scores ë¦¬ìŠ¤íŠ¸ì—ì„œ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤."""
    scores = [fs["score"] for fs in frame_scores if "score" in fs]
    return sum(scores) / len(scores) if scores else 0.0


def _get_grade(avg_score: float) -> str:
    if avg_score >= 0.9:
        return "S"
    elif avg_score >= 0.7:
        return "A"
    elif avg_score >= 0.5:
        return "B"
    return "C"


def _score_summary(avg_score: float, frame_scores: list) -> str:
    if not frame_scores:
        return "í”„ë ˆì„ ë°ì´í„° ì—†ìŒ"
    scores = [fs["score"] for fs in frame_scores]
    return (
        f"- í‰ê· : {avg_score:.1%}\n"
        f"- ìµœê³ : {max(scores):.1%}\n"
        f"- ìµœì €: {min(scores):.1%}\n"
        f"- ë¶„ì„ í”„ë ˆì„ ìˆ˜: {len(scores)}ê°œ"
    )


def _phase_avg_summary(frame_scores: list) -> str:
    """Phaseë³„ í‰ê·  ì ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•œë‹¤."""
    phase_data: Dict[str, list] = {}
    for fs in frame_scores:
        p = fs.get("phase", "unknown")
        phase_data.setdefault(p, []).append(fs["score"])
    if not phase_data:
        return "Phase ë°ì´í„° ì—†ìŒ"
    lines = []
    for phase, scores in sorted(phase_data.items()):
        avg = sum(scores) / len(scores)
        lines.append(f"- **{phase}**: {avg:.1%} ({len(scores)}í”„ë ˆì„)")
    return "\n".join(lines)


def _top_errors_summary(frame_scores: list, top_n: int = 8) -> str:
    """ì˜¤ë¥˜ ë©”ì‹œì§€ ë¹ˆë„ ìƒìœ„ Nê°œë¥¼ ë°˜í™˜í•œë‹¤."""
    error_counts: Dict[str, int] = {}
    for fs in frame_scores:
        for err in fs.get("errors", []):
            error_counts[err] = error_counts.get(err, 0) + 1
    if not error_counts:
        return "ê°ì§€ëœ ì˜¤ë¥˜ ì—†ìŒ âœ…"
    sorted_errors = sorted(error_counts.items(), key=lambda x: -x[1])[:top_n]
    return "\n".join(f"- {err} ({cnt}íšŒ)" for err, cnt in sorted_errors)


def _detail_samples(error_frames: list, max_samples: int = 3) -> str:
    """ì˜¤ë¥˜ í”„ë ˆì„ì—ì„œ ìƒì„¸ ìˆ˜ì¹˜ ìƒ˜í”Œì„ ì¶”ì¶œí•œë‹¤."""
    if not error_frames:
        return "ì˜¤ë¥˜ í”„ë ˆì„ ì—†ìŒ"
    samples = error_frames[:max_samples]
    lines = []
    for ef in samples:
        lines.append(f"### í”„ë ˆì„ {ef['frame_idx']} [{ef.get('phase','?')}] â€” ì ìˆ˜ {ef['score']:.1%}")
        details = ef.get("details", {})
        for k, v in details.items():
            status_icon = "âœ…" if v["status"] == "ok" else "âš ï¸" if v["status"] == "warning" else "âŒ"
            lines.append(f"  {status_icon} {k}: {v['value']} â€” {v['feedback']}")
    return "\n".join(lines)


def _dtw_summary(dtw_result: Optional[dict]) -> str:
    """DTW ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ìš”ì•½í•œë‹¤."""
    if not dtw_result or dtw_result.get("overall_dtw_score") is None:
        return "DTW ë ˆí¼ëŸ°ìŠ¤ ë¯¸ì ìš© (ëª¨ë²” ì˜ìƒ ì—†ìŒ)"
    overall = dtw_result["overall_dtw_score"]
    phase_scores = dtw_result.get("phase_dtw_scores", {})
    lines = [f"- ì „ì²´ ìœ ì‚¬ë„: {overall:.1%}"]
    for phase, score in sorted(phase_scores.items()):
        lines.append(f"  - {phase}: {score:.1%}")
    return "\n".join(lines)


def build_prompt(analysis_results: dict) -> str:
    """
    analysis_results(session_state['analysis_results'])ë¥¼ ë°›ì•„
    Geminiì— ì „ë‹¬í•  ìµœì¢… ìœ ì € í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•œë‹¤.
    """
    frame_scores = analysis_results.get("frame_scores", [])
    error_frames = analysis_results.get("error_frames", [])
    dtw_result = analysis_results.get("dtw_result")

    avg_score = _calc_avg_score(frame_scores)
    grade = _get_grade(avg_score)

    return USER_PROMPT_TEMPLATE.format(
        exercise_type=analysis_results.get("exercise_type", "ì•Œ ìˆ˜ ì—†ìŒ"),
        exercise_count=analysis_results.get("exercise_count", 0),
        avg_posture_score=avg_score,
        grade=grade,
        fps=analysis_results.get("fps", "-"),
        total_frames=analysis_results.get("total_frames", 0),
        score_summary=_score_summary(avg_score, frame_scores),
        phase_avg_summary=_phase_avg_summary(frame_scores),
        top_errors_summary=_top_errors_summary(frame_scores),
        detail_samples=_detail_samples(error_frames),
        dtw_summary=_dtw_summary(dtw_result),
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ğŸš€ Gemini API í˜¸ì¶œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import re

def clean_markdown(text: str) -> str:
    """
    LLM ì‘ë‹µì—ì„œ ë§ˆí¬ë‹¤ìš´ íŠ¹ìˆ˜ë¬¸ì(##, **, *, _, `)ë¥¼ ì œê±°í•˜ê³ 
    í…ìŠ¤íŠ¸ë¥¼ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ëŠ” í›„ì²˜ë¦¬ í•¨ìˆ˜
    """
    if not text:
        return ""

    # 1. ë³¼ë“œì²´, ì´íƒ¤ë¦­ì²´ ê¸°í˜¸ ì œê±° (**, *, __, _)
    # **í…ìŠ¤íŠ¸** -> í…ìŠ¤íŠ¸
    text = re.sub(r'[*_]{1,3}', '', text)

    # 2. í—¤ë” ê¸°í˜¸ ì œê±° (###, ##, #)
    # ## ì œëª© -> ì œëª©
    text = re.sub(r'#{1,6}\s?', '', text)

    # 3. ë°±í‹± ê¸°í˜¸ ì œê±° (`)
    text = re.sub(r'`', '', text)

    # 4. ë¦¬ìŠ¤íŠ¸ ê¸°í˜¸ ì •ë¦¬ (ì„ íƒ ì‚¬í•­)
    # ë¬¸ë‹¨ í˜•ì‹ì„ ì›í•˜ì‹œë¯€ë¡œ - ë‚˜ * ë¡œ ì‹œì‘í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ê¸°í˜¸ë¥¼ ì œê±°í•˜ê±°ë‚˜ ì •ë¦¬
    # text = re.sub(r'^\s*[-*+]\s+', 'â€¢ ', text, flags=re.MULTILINE)

    # 5. ë¶ˆí•„ìš”í•œ ê³µë°± ë° ì¤‘ë³µ ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = text.strip()
    text = re.sub(r'\n{3,}', '\n\n', text) # ì¤„ë°”ê¿ˆì´ 3ê°œ ì´ìƒì´ë©´ 2ê°œë¡œ ì¶•ì†Œ

    return text

def generate_feedback(
    analysis_results: Dict[str, Any],
    api_key: Optional[str] = None,
    temperature: float = 0.7,
    max_output_tokens: int = 6000,
) -> str:
    """
    Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìš´ë™ ìì„¸ í”¼ë“œë°±ì„ ìƒì„±í•œë‹¤.

    Args:
        analysis_results: st.session_state['analysis_results'] dict
        api_key: Gemini API í‚¤ (Noneì´ë©´ .env / í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
        temperature: ìƒì„± ë‹¤ì–‘ì„± (0.0~1.0)
        max_output_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜

    Returns:
        í”¼ë“œë°± ë¬¸ìì—´ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
    """
    # í˜¸ì¶œ ì‹œì ë§ˆë‹¤ .envë¥¼ ë‹¤ì‹œ ì½ì–´ ìµœì‹  í‚¤ë¥¼ ë°˜ì˜
    load_dotenv(override=True)
    key = api_key or os.environ.get("GEMINI_API_KEY", "")

    if not key or not key.strip():
        raise ValueError(
            "Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            "â‘  UIì˜ 'Gemini API ì„¤ì •'ì—ì„œ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜\n"
            "â‘¡ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì— GEMINI_API_KEY=AIza... í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”."
        )

    key = key.strip()
    user_prompt = build_prompt(analysis_results)

    payload = {
        "system_instruction": {
            "parts": [{"text": SYSTEM_PROMPT.strip()}]
        },
        "contents": [
            {
                "role": "user",
                "parts": [{"text": user_prompt}]
            }
        ],
        "generationConfig": {
            "temperature": temperature,
            "maxOutputTokens": max_output_tokens,
        },
    }

    try:
        response = requests.post(
            GEMINI_API_URL,
            params={"key": key},
            headers={"Content-Type": "application/json"},
            json=payload,
            timeout=60,
        )
       

        # HTTP ì˜¤ë¥˜ ì‹œ ì‘ë‹µ ë³¸ë¬¸ì„ ë¨¼ì € í™•ì¸
        if not response.ok:
            status = response.status_code
            try:
                err_body = response.json()
                err_msg = err_body.get("error", {}).get("message", response.text[:300])
            except Exception:
                err_msg = response.text[:300]

            if status == 400:
                raise RuntimeError(f"ìš”ì²­ ì˜¤ë¥˜ (400): {err_msg}")
            elif status == 403:
                raise RuntimeError(f"API í‚¤ ì¸ì¦ ì‹¤íŒ¨ (403): í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n{err_msg}")
            elif status == 429:
                raise RuntimeError(f"ìš”ì²­ í•œë„ ì´ˆê³¼ (429): ì ì‹œ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.\n{err_msg}")
            else:
                raise RuntimeError(f"Gemini API ì˜¤ë¥˜ ({status}): {err_msg}")

        data = response.json()
        candidates = data.get("candidates", [])
        if not candidates:
            raise RuntimeError(f"ì‘ë‹µì— candidates ì—†ìŒ: {json.dumps(data, ensure_ascii=False)[:300]}")

        parts = candidates[0].get("content", {}).get("parts", [])
        feedback_text = "".join(p.get("text", "") for p in parts)
        refined_feedback = clean_markdown(feedback_text)

        if not feedback_text.strip():
            raise RuntimeError(f"ë¹ˆ ì‘ë‹µ ë°˜í™˜. ì „ì²´ ì‘ë‹µ: {json.dumps(data, ensure_ascii=False)[:300]}")

        return refined_feedback

    except requests.exceptions.Timeout:
        raise RuntimeError("ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ). ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except requests.exceptions.ConnectionError as e:
        raise RuntimeError(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨: {e}\nVPNì´ë‚˜ ë°©í™”ë²½ì„ í™•ì¸í•˜ì„¸ìš”.")
    except RuntimeError:
        raise
    except Exception as e:
        raise RuntimeError(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜:\n{traceback.format_exc()}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (python gemini_feedback.py ë¡œ ë‹¨ë… ì‹¤í–‰ ê°€ëŠ¥)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys

    # ë”ë¯¸ ë°ì´í„°ë¡œ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    dummy_results = {
        "exercise_type": "í‘¸ì‹œì—…",
        "exercise_count": 5,
        "fps": 10,
        "total_frames": 120,
        "frame_scores": [
            {"frame_idx": i, "phase": ["top", "descending", "bottom", "ascending"][i % 4],
             "score": 0.6 + (i % 5) * 0.08,
             "errors": ["í—ˆë¦¬ë¥¼ í´ì„¸ìš”"] if i % 3 == 0 else [],
             "details": {"back_angle": {"value": 145.2, "status": "error", "feedback": "í—ˆë¦¬ë¥¼ í´ì„¸ìš”"}}}
            for i in range(20)
        ],
        "error_frames": [
            {"frame_idx": 3, "phase": "bottom", "score": 0.5,
             "errors": ["í—ˆë¦¬ë¥¼ í´ì„¸ìš”", "íŒ”ê¿ˆì¹˜ë¥¼ ëª¸ìª½ìœ¼ë¡œ ëª¨ì•„ì£¼ì„¸ìš”"],
             "details": {
                 "back_angle": {"value": 142.1, "status": "error", "feedback": "í—ˆë¦¬ë¥¼ í´ì„¸ìš”"},
                 "shoulder_abduction": {"value": 85.3, "status": "error", "feedback": "íŒ”ê¿ˆì¹˜ë¥¼ ëª¸ìª½ìœ¼ë¡œ ëª¨ì•„ì£¼ì„¸ìš”"}
             }}
        ],
        "dtw_result": {
            "overall_dtw_score": 0.72,
            "phase_dtw_scores": {"top": 0.80, "bottom": 0.65, "descending": 0.70, "ascending": 0.73},
        },
    }

    print("=" * 60)
    print("ğŸ“‹ ìƒì„±ë  í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
    print("=" * 60)
    print(build_prompt(dummy_results))

    if "--run" in sys.argv:
        print("\n" + "=" * 60)
        print("ğŸ¤– Gemini í”¼ë“œë°± ìƒì„± ì¤‘...")
        print("=" * 60)
        try:
            feedback = generate_feedback(dummy_results)
            print(feedback)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
